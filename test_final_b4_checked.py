from openai import OpenAI
import streamlit as st
import pandas as pd
import numpy as np
import os
from dotenv import load_dotenv
import datetime
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.vectorstores.base import VectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
import re

# openai APIí‚¤ ì…ë ¥
load_dotenv()

client = OpenAI(
    api_key = os.getenv("OPENAI_API_KEY")
)

model = ChatOpenAI(model="gpt-4o-mini")

# csv íŒŒì¼ ë¡œë“œ.
loader_1 = CSVLoader('sum_sum_Cultural2.csv',encoding='UTF8')
loader_2 = CSVLoader('place.csv',encoding='UTF8')

Tresures = loader_1.load()
Travel = loader_2.load()

recursive_text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=10,
    length_function=len,
    is_separator_regex=False,
)

splits = recursive_text_splitter.split_documents(Tresures)
splits += recursive_text_splitter.split_documents(Travel)


embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

if os.path.exists('./db/faiss'):
    vectorstore = FAISS.load_local('./db/faiss', embeddings, allow_dangerous_deserialization=True)
else:
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    vectorstore.save_local('./db/faiss')

retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 1})


# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
contextual_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Please provide detailed, relevant recommendations based on the context provided. Ensure that all recommendations share the same city, district, and road name, and respond only with information from the data provided. Please recommend places in the same city and district. If there are no places in the same district, recommend places in the same city. Be specific and clear in your recommendations Answer in Korean."),
    ("user", "Context: {context}\\n\\nQuestion: {question}. Provide clear and specific recommendations based on the data.")

])




# ë””ë²„ê¹…ì„ ìœ„í•´ ë§Œë“  í´ë˜ìŠ¤
class SimplePassThrough:
    def invoke(self, inputs, **kwargs):
        return inputs

# í”„ë¡¬í”„íŠ¸ í´ë˜ìŠ¤
class ContextToPrompt:
    def __init__(self, prompt_template):
        self.prompt_template = prompt_template

    def invoke(self, inputs):
        # response_docs ë‚´ìš©ì„ trim (ê°€ë…ì„±ì„ ë†’ì—¬ì¤Œ)
        if isinstance(inputs, list): # inputsê°€ listì¸ ê²½ìš°. ì¦‰ ì—¬ëŸ¬ê°œì˜ ë¬¸ì„œë“¤ì´ ê²€ìƒ‰ë˜ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬ëœ ê²½ìš°
            context_text = "\n".join([doc.page_content for doc in inputs]) # \nì„ êµ¬ë¶„ìë¡œ ë„£ì–´ì„œ í•œ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
        else:
            context_text = inputs # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œê²½ìš°ëŠ” ê·¸ëƒ¥ ë¦¬í„´

        # í”„ë¡¬í”„íŠ¸
        formatted_prompt = self.prompt_template.format_messages( # í…œí”Œë¦¿ì˜ ë³€ìˆ˜ì— ì‚½ì…
            context=context_text, # {context} ë³€ìˆ˜ì— context_text, ì¦‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ ì‚½ì…
            question=inputs.get("question", "")
        )
        return formatted_prompt

# Retriever í´ë˜ìŠ¤
class RetrieverWrapper:
    def __init__(self, retriever):
        self.retriever = retriever

    def invoke(self, inputs):
        # 0ë‹¨ê³„ : queryì˜ íƒ€ì…ì— ë”°ë¥¸ ì „ì²˜ë¦¬
        if isinstance(inputs, dict): # inputsê°€ ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì¼ê²½ìš°, question í‚¤ì˜ ê°’ì„ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
            query = inputs.get("question", "")
        else: # ì§ˆë¬¸ì´ ë¬¸ìì—´ë¡œ ì£¼ì–´ì§€ë©´, ê·¸ëŒ€ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
            query = inputs
        # 1ë‹¨ê³„ : queryë¥¼ ë¦¬íŠ¸ë¦¬ë²„ì— ë„£ì–´ì£¼ê³ , response_docsë¥¼ ì–»ê¸°
        response_docs = self.retriever.get_relevant_documents(query) # ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²€ìƒ‰ ê²°ê³¼ë¥¼ response_docsì— ì €ì¥
        return response_docs

# RAG ì²´ì¸ ì„¤ì •
rag_chain_debug = {
    "context": RetrieverWrapper(retriever), # í´ë˜ìŠ¤ ê°ì²´ë¥¼ ìƒì„±í•´ì„œ valueë¡œ ë„£ì–´ì¤Œ
    "prompt": ContextToPrompt(contextual_prompt),
    "llm": model
}


# ì‚¬ì´ë“œ ë°” ì„¤ì •

# ì§€ë„ ì„¤ì •
data = pd.DataFrame({
    'lat':[37.56],
    'lon':[127],
	})

with st.sidebar.expander("ì§€ë„ í¼ì¹˜ê¸°"):
    st.map(data,latitude='lat', longitude='lon')


# ë‚ ì§œ
# ì˜¤ëŠ˜ ë‚ ì§œ ìë™ ì„¤ì •
today = datetime.date.today()

# ì‚¬ì´ë“œë°”ì— ë‚ ì§œ ì…ë ¥ ìœ„ì ¯ì„ ì¶”ê°€í•˜ê³ , ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
st.sidebar.title("ë‹¬ë ¥")
travel_date = st.sidebar.date_input("ë‚ ì§œë¥¼ í´ë¦­ í•˜ì„¸ìš”", today)

    
import time
# ì§„í–‰ë¥  í‘œì‹œ
progress_bar = st.progress(0)

# 100ë²ˆì˜ ë°˜ë³µì„ í†µí•´ ì§„í–‰ë¥  í‘œì‹œ ë° ì‹œê°„ì„ 0.01ì´ˆë¡œ í•´ì„œ ë¹ ë¥¸ ì†ë„ë¡œ ë¡œë”©
for i in range(100):
    time.sleep(0.01)
    progress_bar.progress(i)



# HTMLì„ ì‚¬ìš©í•´ ì œëª©ì„ ê°€ìš´ë° ì •ë ¬
st.markdown("<h1 style='text-align: center;'>77M PROJECTğŸ¤–</h1>", unsafe_allow_html=True)


# ì´ë¯¸ì§€
# ì´ë¯¸ì§€ ìº¡ì…˜ê³¼ í•¨ê»˜ ê°€ìš´ë° ì •ë ¬
st.markdown("""
    <style>
        .centered-image {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
    </style>
    """, unsafe_allow_html=True)

# ì´ë¯¸ì§€ ì¶œë ¥
st.image("ê²½ë³µê¶.jpg", caption="ğŸ¤–ì´ëŸ° ë©‹ì§„ ë¬¸í™”ì¬.. ì£¼ë³€ì— ë¬´ì—‡ì´ ìˆì„ì§€ ê¶ê¸ˆí•˜ì§€ ì•Šë‚˜ìš”?ğŸ¤–", use_container_width=True)

# ê³µì§€ê¸€ í‘œì‹œ (íˆ¬ëª…í•œ ë°°ê²½ê³¼ ì£¼í™©ìƒ‰ ê¸€ì”¨)
st.markdown("""
    <div style="background-color: rgba(255, 255, 255, 0.5); padding: 10px; border-radius: 5px;">
        <strong style="color: orange;">â–¶</strong> ë¬¸í™”ì¬ ì£¼ë³€ì˜ ì—¬í–‰ì§€ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤!<br>  
        ëŒ€í•œë¯¼êµ­ì˜ ê¶ê¸ˆí•œ êµ­ë³´ë‚˜ ë³´ë¬¼ì„ ì…ë ¥í•˜ë©´ ì£¼ë³€ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.<br>  
        " 000ì˜ ê·¼ë°© ì¶”ì²œí•´ì¤˜ "ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”!
    </div>
""", unsafe_allow_html=True)


# ëŒ€í™” ê¸°ë¡ì„ í‚¤ì›Œë“œë³„ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def store_conversation(keyword, message):
    if keyword not in st.session_state.messages:
        st.session_state.messages[keyword] = []
    st.session_state.messages[keyword].append(message)

# ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = {}


# ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ ì²˜ë¦¬
if query := st.chat_input("ëŒ€í•œë¯¼êµ­ì˜ êµ­ë³´ ë˜ëŠ” ë³´ë¬¼ì„ ì…ë ¥í•˜ì‹œê±°ë‚˜ ë¬¼ì–´ë³´ì„¸ìš”"):
    with st.chat_message("user"):
        st.markdown(query)
    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ê°ì§€, 000ì´ë¼ê³  ì‘ì„±í•´ë„ ë˜ëŠ”ì§€ ëª°ë¼ì„œ ì¼ë‹¨ ë³€ìˆ˜xë¼ê³  ì‘ì„±. "xì˜ ê·¼ë°© ì¶”ì²œí•´ì¤˜"ì—ì„œ x ê°€ì ¸ì˜¤ê¸° ì „ì— í•˜ëŠ” ì‘ì—…?
    match = re.match(r"(\S+)\s*ì˜\s*ê·¼ë°©\s*ì¶”ì²œí•´ì¤˜", query)
    if match:
        # 'x'ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        keyword = match.group(1)
    # ê°€ì ¸ì˜¨ í‚¤ì›Œë“œì— ëŒ€í•´ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥
        store_conversation(keyword, {"role": "user", "content": query})

    # 1. ë¦¬íŠ¸ë¦¬ë²„ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ response_docsì— ì €ì¥
    response_docs = rag_chain_debug["context"].invoke({"question": query})

    # 2. í”„ë¡¬í”„íŠ¸ì— ì§ˆë¬¸ê³¼ response_docsë¥¼ ë„£ì–´ì„œ ì‘ë‹µì„ ìƒì„±
    prompt_messages = rag_chain_debug["prompt"].invoke({
    "context": response_docs,
    "question": query
    })

    # 3. ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ LLMì— ë„£ì–´ ì‘ë‹µì„ ìƒì„±
    response = rag_chain_debug["llm"].invoke(prompt_messages)
    # ê°€ì ¸ì˜¨ í‚¤ì›Œë“œì— ëŒ€í•´ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µë„ ì €ì¥
    store_conversation(keyword, {"role": "assistant", "content": response.content})

    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("assistant"):
        if response and hasattr(response, 'content') and response.content:
            st.markdown(response.content)
        else:
            st.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”ì— í´ë¦­ ê°€ëŠ¥í•œ í‚¤ì›Œë“œë¥¼ í‘œì‹œ(ëŒ€í™” ë‚´ìš©ì— ë§ì¶°ì„œ)
st.sidebar.title("ëŒ€í™” ê¸°ë¡")
for keyword in st.session_state.messages.keys():
    if st.sidebar.button(keyword):
        # í‚¤ì›Œë“œë¥¼ í´ë¦­í•˜ë©´ í•´ë‹¹ í‚¤ì›Œë“œì— ê´€ë ¨ëœ ëŒ€í™” ë‚´ì—­ì„ í‘œì‹œ
            for msg in st.session_state.messages[keyword]:
                st.sidebar.markdown(f"**{msg['role']}**: {msg['content']}")












  
    
    
    
    
