{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key 입력:  ········\n"
     ]
    }
   ],
   "source": [
    "#1. 사용환경 준비\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \") # API 키 입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델 로드하기 \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Travel_spot.csv', 'row': 0}, page_content='title: 구인사(단양)\\naddress: 충청북도 단양군 영춘면 구인사길 73\\ntelNo: ')]\n"
     ]
    }
   ],
   "source": [
    "#3. 문서 로드하기\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = CSVLoader(\"Cultural_asset.csv\",encoding='UTF8')\n",
    "loader2 = CSVLoader(\"Travel_spot.csv\",encoding='UTF8')\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "Treasures = loader.load()\n",
    "Travel = loader2.load()\n",
    "print(Travel[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='title: 원대리 자작나무 숲 (속삭이는 자작나무 숲)\n",
      "address: 강원특별자치도 인제군 인제읍 자작나무숲길 760\n",
      "telNo: 자작나무숲 안내소 033-463-0044' metadata={'source': 'Travel_spot.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "#4. 문서 청크로 나누기(CharacterTextSplitter)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "\n",
    "# 텍스트 청크 분할기 설정 (문단 기준 분할)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(Treasures) # 문서를 청크로 분할\n",
    "splits2 = text_splitter.split_documents(Travel)\n",
    "print(splits2[1]) # 상위 10개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. 벡터 스토어 생성\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 문서에서 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. FAISS를 Retriever로 변환\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 프롬프트 템플릿을 정의하라\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_2004\\585062412.py:40: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=model, prompt=contextual_prompt)\n"
     ]
    }
   ],
   "source": [
    "#9. LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성하라. \n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "class SimplePassThrough:\n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "class ContextToPrompt:\n",
    "    def __init__(self, prompt_template):\n",
    "        self.prompt_template = prompt_template\n",
    "    \n",
    "    def invoke(self, inputs):\n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs])\n",
    "        else:\n",
    "            context_text = inputs\n",
    "        \n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text,\n",
    "            question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\")\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_Treasures = self.retriever.get_relevant_documents(query)\n",
    "        return response_Treasures\n",
    "#텍스트 생성 체인 생성\n",
    "llm_chain = LLMChain(llm=model, prompt=contextual_prompt)\n",
    "\n",
    "# RAG 체인 설정\n",
    "rag_chain_debug = {\n",
    "    \"context\": RetrieverWrapper(retriever),\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt),\n",
    "    \"llm\": model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG(생성형 응답 생성)의 필요성\n",
    "\n",
    "RAG는 정보 검색과 생성 모델을 결합하여 사용자 질문에 대한 보다 정확하고 관련성 높은 답변을 생성하는 기술이다. RAG의 필요성은 다음과 같은 이유로 설명할 수 있다.\n",
    "\n",
    "1. **정보의 동적 접근**: RAG는 최신 정보를 실시간으로 검색할 수 있어, 사용자가 요청하는 질문에 대해 항상 최신의 정확한 정보를 제공할 수 있다.\n",
    "\n",
    "2. **맥락 이해**: 사용자 질문에 대한 답변을 생성할 때, RAG는 관련된 맥락을 기반으로 하여 보다 깊이 있는 이해를 제공합니다. 이는 단순한 정답 제공을 넘어, 질문의 의도를 파악하여 적절한 답변을 생성하는 데 기여한다.\n",
    "\n",
    "3. **대량의 데이터 처리**: RAG는 대량의 문서와 정보를 처리할 수 있는 능력을 가지고 있어, 사용자가 원하는 다양한 주제에 대해 신속하게 대응할 수 있다.\n",
    "\n",
    "4. **개선된 사용자 경험**: RAG를 통해 제공되는 답변은 보다 개인화되고 관련성이 높아, 사용자 경험을 개선할 수 있다. 이는 사용자 만족도를 높이고, 반복적인 질문을 줄이는 데 도움이 된다.\n",
    "\n",
    "결론적으로, RAG는 정보 검색과 생성 모델의 장점을 결합하여, 더 나은 품질의 질문 응답 시스템을 구축하는 데 필수적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  울산에 있는 국보와 보물들 리스트를 알려줘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_2004\\585062412.py:37: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_Treasures = self.retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 울산에 있는 국보와 보물들 리스트를 알려줘\n",
      "\n",
      "답변:\n",
      "주어진 맥락에는 울산에 있는 국보와 보물에 대한 정보가 포함되어 있지 않습니다. 따라서 울산의 국보와 보물 리스트를 제공할 수 없습니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  울산에 있는 문화재를 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 울산에 있는 문화재를 알려줘\n",
      "\n",
      "답변:\n",
      "제공된 정보에는 울산에 있는 문화재에 대한 내용이 포함되어 있지 않습니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  울산\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 울산\n",
      "\n",
      "답변:\n",
      "울산광역시 북구에 위치한 울산 신흥사 석조아미타여래좌상(蔚山 新興寺 石造阿彌陀如來坐像)입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  경주\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 경주\n",
      "\n",
      "답변:\n",
      "The provided context does not contain any information about 경주 (Gyeongju). It only mentions a cultural asset located in 부여 (Buyeo).\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  서울\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 서울\n",
      "\n",
      "답변:\n",
      "The context mentions \"서울 숭례문\" which is located in \"서울 중구 세종대로 40 (남대문로4가)\".\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  서울에 있는 문화재 모든 목록을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 서울에 있는 문화재 모든 목록을 알려줘\n",
      "\n",
      "답변:\n",
      "서울에 있는 문화재 목록은 다음과 같습니다:\n",
      "\n",
      "1. 삼국사기(三國史記) - 위치: 서울 중구 세종대로21길 22 (태평로1가, 성암고서박물관)\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  서울 근처에있는 문화재 목록을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 서울 근처에있는 문화재 목록을 알려줘\n",
      "\n",
      "답변:\n",
      "서울 근처에 있는 문화재 목록은 다음과 같습니다:\n",
      "\n",
      "1. 삼국사기(三國史記)\n",
      "   - 번호: 322-2호\n",
      "   - 위치: 서울 중구 세종대로21길 22 (태평로1가, 성암고서박물관)\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  왜 1개 밖에 안나와?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 왜 1개 밖에 안나와?\n",
      "\n",
      "답변:\n",
      "제공된 문맥에서 확인할 수 있는 정보는 하나의 문화 자산에 대한 내용입니다. 'Cultural_asset.csv' 파일에서 2081번째 행에 대한 정보만 포함되어 있어, 그 결과로 1개의 항목만 나타나는 것입니다. 추가적인 문화 자산에 대한 정보가 없기 때문에 1개 밖에 나오지 않는 것으로 보입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  여러개 검색하려면 어떡해야하지\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 여러개 검색하려면 어떡해야하지\n",
      "\n",
      "답변:\n",
      "여러 개를 검색하려면, 각각의 검색어를 입력할 때 'AND', 'OR' 등의 논리 연산자를 사용하거나, 검색할 항목을 쉼표로 구분하여 입력하면 됩니다. 추가적으로, 여러 개의 키워드를 포함한 쿼리를 작성하여 검색 결과를 좁힐 수 있습니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 :  예를 들어줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 예를 들어줘\n",
      "\n",
      "답변:\n",
      "예를 들어, 음주전문춘추괄례시말좌전구독직해 권62~70은 서울 용산구 서빙고로 137에 위치한 국립중앙박물관에서 소장하고 있는 문화 자산입니다.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "#10. 질문에 응답하는 챗봇을 구동하여 질문해라. \n",
    "\n",
    "# 챗봇 구동\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "    if query == \"종료\": # 종료 입력 시 챗봇 종료\n",
    "        break\n",
    "    \n",
    "    # 1. Retriever로 관련 문서 검색\n",
    "    response_Treasures = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "    \n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = rag_chain_debug[\"prompt\"].invoke({\n",
    "        \"context\": response_Treasures,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "    \n",
    "    print(\"\\n질문:\",query)\n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content) # 답변 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
