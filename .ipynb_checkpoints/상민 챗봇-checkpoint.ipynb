{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 사용환경 준비\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \") # API 키 입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델 로드하기 \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'place.csv', 'row': 0}, page_content='title: 구인사(단양)\\naddress: 충청북도 단양군 영춘면 구인사길 73\\ntelNo: ')]\n"
     ]
    }
   ],
   "source": [
    "#3. 문서 로드하기\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = CSVLoader(\"sum_sum_Cultural2.csv\",encoding='UTF8')\n",
    "loader2 = CSVLoader(\"place.csv\",encoding='UTF8')\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "Treasures = loader.load()\n",
    "Travel = loader2.load()\n",
    "print(Travel[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='title: 원대리 자작나무 숲 (속삭이는 자작나무 숲)\n",
      "address: 강원특별자치도 인제군 인제읍 자작나무숲길 760\n",
      "telNo: 자작나무숲 안내소 033-463-0044' metadata={'source': 'place.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "#4. 문서 청크로 나누기(CharacterTextSplitter)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "\n",
    "# 텍스트 청크 분할기 설정 (문단 기준 분할)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(Treasures) # 문서를 청크로 분할\n",
    "splits2 = text_splitter.split_documents(Travel)\n",
    "print(splits2[1]) # 상위 10개만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharacterTextSplitter 청킹 방식 및 매개변수 설명\n",
    "\n",
    "## 청킹 방식\n",
    "`CharacterTextSplitter`는 텍스트를 지정된 기준에 따라 나누어 작은 조각(청크)으로 만드는 기능을 제공한다. 이 방식은 대량의 텍스트를 처리할 때 유용합니다.\n",
    "\n",
    "## 매개변수 설명\n",
    "\n",
    "1. **separator**: \n",
    "   - **설명**: 문서를 나눌 기준으로 사용할 문자열을 설정한다는 뜻이다.\n",
    "\n",
    "2. **chunk_size**:\n",
    "   - **설명**: 각 청크의 최대 크기를 설정한다. 청크는 이 크기를 초과하지 않는다.\n",
    "\n",
    "3. **chunk_overlap**:\n",
    "   - **설명**: 청크 간의 겹치는 글자 수를 설정한다. 문맥을 유지하는 데 도움이 된다.\n",
    "\n",
    "\n",
    "4. **length_function**:\n",
    "   - **설명**: 청크의 길이를 계산하는 함수이다. 일반적으로 문자열 길이를 계산하는 `len` 함수를 사용한다.\n",
    "\n",
    "\n",
    "5. **is_separator_regex**:\n",
    "   - **설명**: 구분자가 정규 표현식인지 여부를 설정한다. `False`로 설정하면 일반 문자열로 처리된다.\n",
    "\n",
    "\n",
    "## 사용 목적\n",
    "이 과정을 통해 대량의 텍스트를 효과적으로 처리하고, AI 모델이 이해할 수 있는 형태로 변환하여 정보 추출 및 분석을 용이하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. 벡터 스토어 생성\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 문서에서 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. FAISS를 Retriever로 변환\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 프롬프트 템플릿을 정의하라\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성하라. \n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "class SimplePassThrough:\n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "class ContextToPrompt:\n",
    "    def __init__(self, prompt_template):\n",
    "        self.prompt_template = prompt_template\n",
    "    \n",
    "    def invoke(self, inputs):\n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs])\n",
    "        else:\n",
    "            context_text = inputs\n",
    "        \n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text,\n",
    "            question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\")\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_Treasures = self.retriever.get_relevant_documents(query)\n",
    "        return response_Treasures\n",
    "#텍스트 생성 체인 생성\n",
    "llm_chain = LLMChain(llm=model, prompt=contextual_prompt)\n",
    "\n",
    "# RAG 체인 설정\n",
    "rag_chain_debug = {\n",
    "    \"context\": RetrieverWrapper(retriever),\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt),\n",
    "    \"llm\": model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG(생성형 응답 생성)의 필요성\n",
    "\n",
    "RAG는 정보 검색과 생성 모델을 결합하여 사용자 질문에 대한 보다 정확하고 관련성 높은 답변을 생성하는 기술이다. RAG의 필요성은 다음과 같은 이유로 설명할 수 있다.\n",
    "\n",
    "1. **정보의 동적 접근**: RAG는 최신 정보를 실시간으로 검색할 수 있어, 사용자가 요청하는 질문에 대해 항상 최신의 정확한 정보를 제공할 수 있다.\n",
    "\n",
    "2. **맥락 이해**: 사용자 질문에 대한 답변을 생성할 때, RAG는 관련된 맥락을 기반으로 하여 보다 깊이 있는 이해를 제공합니다. 이는 단순한 정답 제공을 넘어, 질문의 의도를 파악하여 적절한 답변을 생성하는 데 기여한다.\n",
    "\n",
    "3. **대량의 데이터 처리**: RAG는 대량의 문서와 정보를 처리할 수 있는 능력을 가지고 있어, 사용자가 원하는 다양한 주제에 대해 신속하게 대응할 수 있다.\n",
    "\n",
    "4. **개선된 사용자 경험**: RAG를 통해 제공되는 답변은 보다 개인화되고 관련성이 높아, 사용자 경험을 개선할 수 있다. 이는 사용자 만족도를 높이고, 반복적인 질문을 줄이는 데 도움이 된다.\n",
    "\n",
    "결론적으로, RAG는 정보 검색과 생성 모델의 장점을 결합하여, 더 나은 품질의 질문 응답 시스템을 구축하는 데 필수적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "질문: 숭례문 주변 여행지가 어디 있을까?\n",
      "\n",
      "답변:\n",
      "숭례문 주변 여행지로는 경복궁, 덕수궁, 남산서울타워, 명동 등이 있습니다.\n",
      "========================\n",
      "\n",
      "질문: 부산 관련 국보나 보물은 뭐가 있을까?\n",
      "\n",
      "답변:\n",
      "부산 관련 국보나 보물로는 '조선왕조실록 태백산사고본'이 있습니다. 이 문서는 부산 연제구의 국가기록원 역사기록관에 위치해 있습니다.\n",
      "========================\n",
      "\n",
      "질문: 그럼 거기 관련 여행지는 뭐가 있을까?\n",
      "\n",
      "답변:\n",
      "해당 지역인 경기 성남시 분당구 하오개로에 위치한 한국학중앙연구원 주변의 관련 여행지는 다음과 같습니다:\n",
      "\n",
      "1. 한국학중앙연구원 - 한국의 역사와 문화에 대한 연구와 자료를 제공하는 기관으로, 다양한 전시와 행사도 열립니다.\n",
      "2. 성남시청 - 지역의 행정과 문화 행사 관련 정보를 접할 수 있는 곳입니다.\n",
      "3. 분당 중앙공원 - 자연을 즐기고 산책할 수 있는 공원으로, 여유로운 시간을 보낼 수 있습니다.\n",
      "4. 판교 스타필드 - 쇼핑과 다양한 레저 시설이 있는 복합 공간으로, 가족 단위 방문객에게 적합합니다.\n",
      "\n",
      "이 외에도 성남시는 다양한 문화재와 공원, 카페 등이 있어 여행지로 탐방하기에 좋은 곳입니다.\n",
      "========================\n",
      "\n",
      "질문: 조선왕조실록 태백산사고본 근처 여행지를 알려줘\n",
      "\n",
      "답변:\n",
      "조선왕조실록 태백산사고본은 부산 연제구 경기장로 28에 위치한 국가기록원 역사기록관에 있습니다. 이 지역 근처의 여행지로는 부산의 유명한 관광지인 광안리 해수욕장, 해운대 해수욕장, 그리고 부산타워가 있습니다. 또한, 근처에 있는 연산동의 동래 온천과 같은 명소도 방문할 수 있습니다.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "#10. 질문에 응답하는 챗봇을 구동하여 질문해라. \n",
    "\n",
    "# 챗봇 구동\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "    if query == \"종료\": # 종료 입력 시 챗봇 종료\n",
    "        break\n",
    "    \n",
    "    # 1. Retriever로 관련 문서 검색\n",
    "    response_Treasures = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "    \n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = rag_chain_debug[\"prompt\"].invoke({\n",
    "        \"context\": response_Treasures,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "    \n",
    "    print(\"\\n질문:\",query)\n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content) # 답변 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
